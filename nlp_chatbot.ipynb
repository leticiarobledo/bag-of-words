{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Chatbot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet # to perform lemmitization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
    "from nltk import pos_tag # for parts of speech\n",
    "from sklearn.metrics import pairwise_distances # to perfrom cosine similarity\n",
    "from nltk import word_tokenize # to create tokens\n",
    "from nltk.corpus import stopwords # for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download if required\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context  \\\n",
       "0  Tell me about your personality   \n",
       "1       I want to know you better   \n",
       "2                 Define yourself   \n",
       "3               Describe yourself   \n",
       "4          tell me about yourself   \n",
       "\n",
       "                                   Text Response  \n",
       "0    Just think of me as the ace up your sleeve.  \n",
       "1  I can help you work smarter instead of harder  \n",
       "2                                            NaN  \n",
       "3                                            NaN  \n",
       "4                                            NaN  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('queries_and_responses.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>can we chat</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be back in a few minutes</td>\n",
       "      <td>I'll be waiting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>I'll be back</td>\n",
       "      <td>All right. I'll be here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>I'll get back to you in a moment</td>\n",
       "      <td>Till next time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>I promise to come back</td>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Context  \\\n",
       "0       Tell me about your personality   \n",
       "1            I want to know you better   \n",
       "2                      Define yourself   \n",
       "3                    Describe yourself   \n",
       "4               tell me about yourself   \n",
       "...                                ...   \n",
       "1587                       can we chat   \n",
       "1588     I'll be back in a few minutes   \n",
       "1589                      I'll be back   \n",
       "1590  I'll get back to you in a moment   \n",
       "1591            I promise to come back   \n",
       "\n",
       "                                      Text Response  \n",
       "0       Just think of me as the ace up your sleeve.  \n",
       "1     I can help you work smarter instead of harder  \n",
       "2     I can help you work smarter instead of harder  \n",
       "3     I can help you work smarter instead of harder  \n",
       "4     I can help you work smarter instead of harder  \n",
       "...                                             ...  \n",
       "1587                     Talking is what I do best.  \n",
       "1588                               I'll be waiting.  \n",
       "1589                       All right. I'll be here.  \n",
       "1590                                Till next time.  \n",
       "1591               Okay. You know where to find me.  \n",
       "\n",
       "[1592 rows x 2 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in missing responses -> Replaces every null value with the previous row's response\n",
    "df.ffill(axis = 0,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tell', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('about', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('personality', 'NN')]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign syntactic attribute of each word\n",
    "s = 'tell me about your personality'\n",
    "pos_tag(nltk.word_tokenize(s),tagset = None) # returns the parts of speech of every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absorb'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lemmatizer so each token is converted to its root\n",
    "lemma = wordnet.WordNetLemmatizer()\n",
    "lemma.lemmatize('absorbed', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs text normalization steps\n",
    "\n",
    "def normalization(text):\n",
    "    \n",
    "    text = str(text).lower() # text to lower case\n",
    "    clean_text = re.sub(r'[^ a-z]','',text) # removing special characters\n",
    "    tokens = nltk.word_tokenize(clean_text) # word tokenizing\n",
    "    \n",
    "    lema = wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    lema_words = []\n",
    "    \n",
    "    tags_list = pos_tag(tokens,tagset=None) # parts of speech\n",
    "    \n",
    "    # Lemmatize all the words in given sentence by assigning correct category\n",
    "    for token,syntactic_func in tags_list:\n",
    "        if syntactic_func.startswith('V'):  # Verb\n",
    "            pos_val = 'v'\n",
    "        elif syntactic_func.startswith('J'): # Adj\n",
    "            pos_val = 'a'\n",
    "        elif syntactic_func.startswith('R'): # Adverb\n",
    "            pos_val = 'r'\n",
    "        else:\n",
    "            pos_val = 'n' # Noun\n",
    "        lemmatized_word = lema.lemmatize(token, pos_val) # lemmatize\n",
    "        lema_words.append(lemmatized_word) # appending the lemmatized token\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i be think about what you will be tell me'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test of normalization function\n",
    "normalization('i was thinking about what you will be telling me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "      <th>Lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>I need to talk to you</td>\n",
       "      <td>Good conversation really makes my day.</td>\n",
       "      <td>i need to talk to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>I want to speak with you</td>\n",
       "      <td>I'm always here to lend an ear.</td>\n",
       "      <td>i want to speak with you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>let's have a discussion</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>let have a discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>I just want to talk</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>i just want to talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>let's discuss something</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>let discuss something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>can I speak</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can i speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>can we talk</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can we talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>let's talk</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>let talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>I want to talk to you</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>i want to talk to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>can we chat</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can we chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>can we chat</td>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>can we chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be back in a few minutes</td>\n",
       "      <td>I'll be waiting.</td>\n",
       "      <td>ill be back in a few minute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>I'll be back</td>\n",
       "      <td>All right. I'll be here.</td>\n",
       "      <td>ill be back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>I'll get back to you in a moment</td>\n",
       "      <td>Till next time.</td>\n",
       "      <td>ill get back to you in a moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>I promise to come back</td>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>i promise to come back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Context  \\\n",
       "1577             I need to talk to you   \n",
       "1578          I want to speak with you   \n",
       "1579           let's have a discussion   \n",
       "1580               I just want to talk   \n",
       "1581           let's discuss something   \n",
       "1582                       can I speak   \n",
       "1583                       can we talk   \n",
       "1584                        let's talk   \n",
       "1585             I want to talk to you   \n",
       "1586                       can we chat   \n",
       "1587                       can we chat   \n",
       "1588     I'll be back in a few minutes   \n",
       "1589                      I'll be back   \n",
       "1590  I'll get back to you in a moment   \n",
       "1591            I promise to come back   \n",
       "\n",
       "                               Text Response                  Lemmatized_text  \n",
       "1577  Good conversation really makes my day.            i need to talk to you  \n",
       "1578         I'm always here to lend an ear.         i want to speak with you  \n",
       "1579              Talking is what I do best.            let have a discussion  \n",
       "1580              Talking is what I do best.              i just want to talk  \n",
       "1581              Talking is what I do best.            let discuss something  \n",
       "1582              Talking is what I do best.                      can i speak  \n",
       "1583              Talking is what I do best.                      can we talk  \n",
       "1584              Talking is what I do best.                         let talk  \n",
       "1585              Talking is what I do best.            i want to talk to you  \n",
       "1586              Talking is what I do best.                      can we chat  \n",
       "1587              Talking is what I do best.                      can we chat  \n",
       "1588                        I'll be waiting.      ill be back in a few minute  \n",
       "1589                All right. I'll be here.                      ill be back  \n",
       "1590                         Till next time.  ill get back to you in a moment  \n",
       "1591        Okay. You know where to find me.           i promise to come back  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize whole dataset (user input text)\n",
    "df['Lemmatized_text'] = df['Context'].apply(normalization)\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition: with corpus of words and frequency of these, we can compare similarity between documents and learn information form these documents throught the presence of the 'target words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was the best of times',\n",
       " 'it was the worst of times',\n",
       " 'it was the age of wisdom',\n",
       " 'it was the age of foolishness']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Attempt of BoW model with small corpus of text (model intuition from https://machinelearningmastery.com/gentle-introduction-bag-words-model/)\n",
    "c = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness\"\n",
    "corpus = [i for i in c.split(', ')]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0, 1, 1, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0, 1, 0, 1]]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vector using target words\n",
    "targets = ['it', 'was', 'the', 'best', 'of', 'times', 'worst', 'age', 'wisdom', 'foolishness']\n",
    "vectors = []\n",
    "for verse in corpus:\n",
    "    vector = []\n",
    "    verse = [i for i in verse.lower().split()]\n",
    "    for word in targets:\n",
    "        if word in verse:\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    vectors.append(vector)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NLTK and current corpus to apply BOW model to chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abort</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>actually</th>\n",
       "      <th>adore</th>\n",
       "      <th>advice</th>\n",
       "      <th>advise</th>\n",
       "      <th>affirmative</th>\n",
       "      <th>afraid</th>\n",
       "      <th>...</th>\n",
       "      <th>yeh</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows Ã— 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abort  about  absolutely  abysmal  actually  adore  advice  advise  \\\n",
       "0         0      1           0        0         0      0       0       0   \n",
       "1         0      0           0        0         0      0       0       0   \n",
       "2         0      0           0        0         0      0       0       0   \n",
       "3         0      0           0        0         0      0       0       0   \n",
       "4         0      1           0        0         0      0       0       0   \n",
       "...     ...    ...         ...      ...       ...    ...     ...     ...   \n",
       "1587      0      0           0        0         0      0       0       0   \n",
       "1588      0      0           0        0         0      0       0       0   \n",
       "1589      0      0           0        0         0      0       0       0   \n",
       "1590      0      0           0        0         0      0       0       0   \n",
       "1591      0      0           0        0         0      0       0       0   \n",
       "\n",
       "      affirmative  afraid  ...  yeh  yep  yes  yet  you  your  youre  yours  \\\n",
       "0               0       0  ...    0    0    0    0    0     1      0      0   \n",
       "1               0       0  ...    0    0    0    0    1     0      0      0   \n",
       "2               0       0  ...    0    0    0    0    0     0      0      0   \n",
       "3               0       0  ...    0    0    0    0    0     0      0      0   \n",
       "4               0       0  ...    0    0    0    0    0     0      0      0   \n",
       "...           ...     ...  ...  ...  ...  ...  ...  ...   ...    ...    ...   \n",
       "1587            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "1588            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "1589            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "1590            0       0  ...    0    0    0    0    1     0      0      0   \n",
       "1591            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "\n",
       "      yourself  yup  \n",
       "0            0    0  \n",
       "1            0    0  \n",
       "2            1    0  \n",
       "3            1    0  \n",
       "4            1    0  \n",
       "...        ...  ...  \n",
       "1587         0    0  \n",
       "1588         0    0  \n",
       "1589         0    0  \n",
       "1590         0    0  \n",
       "1591         0    0  \n",
       "\n",
       "[1592 rows x 505 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use CountVectorizer method to improve performance\n",
    "cv = CountVectorizer() # intializing the count vectorizer\n",
    "X = cv.fit_transform(df['Lemmatized_text']).toarray()\n",
    "# returns all the unique word from data \n",
    "features = cv.get_feature_names()\n",
    "df_bow = pd.DataFrame(X, columns = features)\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Are you a bot'\n",
    "query1 ='Will you help me and tell me more about yourself' \n",
    "Q = []\n",
    "a = query.split()\n",
    "for i in a:\n",
    "    if i in stopwords.words('english'):\n",
    "        continue\n",
    "    else:\n",
    "        Q.append(i)\n",
    "    b=\" \".join(Q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_lemma = normalization(b) # applying the function that we created for text normalizing\n",
    "query_BOW = cv.transform([query_lemma]).toarray() # applying bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use trigonometric functions (cosine similarity) to determine 0-1 value of each vector, facilitating comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.40824829],\n",
       "       [0.        ],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity for the test query\n",
    "cosine_value = 1 - pairwise_distances(df_bow, query_BOW, metric = 'cosine' )\n",
    "(cosine_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_bow'] = cosine_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Talking is what I do best.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>I'll be waiting.</td>\n",
       "      <td>0.288675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>All right. I'll be here.</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Till next time.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Response  similarity_bow\n",
       "0       Just think of me as the ace up your sleeve.        0.000000\n",
       "1     I can help you work smarter instead of harder        0.000000\n",
       "2     I can help you work smarter instead of harder        0.000000\n",
       "3     I can help you work smarter instead of harder        0.000000\n",
       "4     I can help you work smarter instead of harder        0.000000\n",
       "...                                             ...             ...\n",
       "1587                     Talking is what I do best.        0.000000\n",
       "1588                               I'll be waiting.        0.288675\n",
       "1589                       All right. I'll be here.        0.408248\n",
       "1590                                Till next time.        0.000000\n",
       "1591               Okay. You know where to find me.        0.000000\n",
       "\n",
       "[1592 rows x 2 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi = pd.DataFrame(df, columns=['Text Response','similarity_bow']) # taking similarity value of responses for the question we took\n",
    "df_simi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Lovely, thanks.</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>Excellent! That's what I like to see.</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Text Response  similarity_bow\n",
       "226   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "228   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "224   Indeed I am. I'll be here whenever you need me.        0.707107\n",
       "1228                                  Lovely, thanks.        0.534522\n",
       "1363            Excellent! That's what I like to see.        0.500000"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi_sort = df_simi.sort_values(by='similarity_bow', ascending=False) # sorting the values\n",
    "df_simi_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Lovely, thanks.</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>Excellent! That's what I like to see.</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>You're pretty smart yourself.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>You're pretty smart yourself.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Thank you. I try my best.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>You're pretty smart yourself.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Text Response  similarity_bow\n",
       "226   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "228   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "224   Indeed I am. I'll be here whenever you need me.        0.707107\n",
       "1228                                  Lovely, thanks.        0.534522\n",
       "1363            Excellent! That's what I like to see.        0.500000\n",
       "...                                               ...             ...\n",
       "255                     You're pretty smart yourself.        0.353553\n",
       "14      I can help you work smarter instead of harder        0.353553\n",
       "259                     You're pretty smart yourself.        0.353553\n",
       "232                         Thank you. I try my best.        0.353553\n",
       "235                     You're pretty smart yourself.        0.353553\n",
       "\n",
       "[330 rows x 2 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.35 # considering the value of p=smiliarity > 0.35\n",
    "df_threshold = df_simi_sort[df_simi_sort['similarity_bow'] > threshold] \n",
    "df_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_value = cosine_value.argmax() # index in dataframe of of highest similarity\n",
    "index_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you a bot'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Indeed I am. I'll be here whenever you need me.\""
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text Response'].loc[index_value] # Get response for highest-similarity index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will help tell'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that removes stop words and process the corpus\n",
    "def stopword_(text):      \n",
    "    lema = wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    lema_words = []\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text) # word tokenizing\n",
    "    tags_list = pos_tag(tokens,tagset=None) # parts of speech\n",
    "    \n",
    "    words_to_remove = stopwords.words('english')\n",
    "    \n",
    "    # Lemmatize all the words in given sentence by assigning correct category\n",
    "    for token,syntactic_func in tags_list:\n",
    "        if token in words_to_remove:\n",
    "            continue\n",
    "        if syntactic_func.startswith('V'):  # Verb\n",
    "            pos_val = 'v'\n",
    "        elif syntactic_func.startswith('J'): # Adj\n",
    "            pos_val = 'a'\n",
    "        elif syntactic_func.startswith('R'): # Adverb\n",
    "            pos_val = 'r'\n",
    "        else:\n",
    "            pos_val = 'n' # Noun\n",
    "        lemmatized_word = lema.lemmatize(token, pos_val) # lemmatize\n",
    "        lema_words.append(lemmatized_word) # append the lemmatized token\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence \n",
    "stopword_(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm glad to help. What can I do for you?\""
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns response to query using BOW model\n",
    "\n",
    "def chat(text):\n",
    "    s = stopword_(text)\n",
    "    lemma = text_normalization(s) # calling the function to perform text normalization\n",
    "    bow=cv.transform([lemma]).toarray() # applying bow\n",
    "    cosine_value = 1- pairwise_distances(df_bow,bow, metric = 'cosine' )\n",
    "    index_value=cosine_value.argmax() # getting index value \n",
    "    return df['Text Response'].loc[index_value]\n",
    "chat(query1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
