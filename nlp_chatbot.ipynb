{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Chatbot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import wordnet # to perform lemmitization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
    "from nltk import pos_tag # for parts of speech\n",
    "from sklearn.metrics import pairwise_distances # to perfrom cosine similarity\n",
    "from nltk import word_tokenize # to create tokens\n",
    "from nltk.corpus import stopwords # for stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\letic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download if required\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context  \\\n",
       "0  Tell me about your personality   \n",
       "1       I want to know you better   \n",
       "2                 Define yourself   \n",
       "3               Describe yourself   \n",
       "4          tell me about yourself   \n",
       "\n",
       "                                       Text Response  \n",
       "0        Just think of me as the ace up your sleeve.  \n",
       "1  I am a bot. I am designed to keep conversation...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('queries_and_responses.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Do you have family</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>Are there others like you</td>\n",
       "      <td>Of course. That's why we're here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Do you want to take over the world</td>\n",
       "      <td>Of course. That's why we're here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>Who are we?</td>\n",
       "      <td>You don't need to know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Who is we?</td>\n",
       "      <td>You don't need to know</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Context  \\\n",
       "0         Tell me about your personality   \n",
       "1              I want to know you better   \n",
       "2                        Define yourself   \n",
       "3                      Describe yourself   \n",
       "4                 tell me about yourself   \n",
       "...                                  ...   \n",
       "1599                  Do you have family   \n",
       "1600           Are there others like you   \n",
       "1601  Do you want to take over the world   \n",
       "1602                         Who are we?   \n",
       "1603                          Who is we?   \n",
       "\n",
       "                                          Text Response  \n",
       "0           Just think of me as the ace up your sleeve.  \n",
       "1     I am a bot. I am designed to keep conversation...  \n",
       "2     I am a bot. I am designed to keep conversation...  \n",
       "3     I am a bot. I am designed to keep conversation...  \n",
       "4     I am a bot. I am designed to keep conversation...  \n",
       "...                                                 ...  \n",
       "1599                                                 No  \n",
       "1600                   Of course. That's why we're here  \n",
       "1601                   Of course. That's why we're here  \n",
       "1602                             You don't need to know  \n",
       "1603                             You don't need to know  \n",
       "\n",
       "[1604 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in missing responses -> Replaces every null value with the previous row's response\n",
    "df.ffill(axis = 0,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tell', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('about', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('personality', 'NN')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign syntactic attribute of each word\n",
    "s = 'tell me about your personality'\n",
    "pos_tag(nltk.word_tokenize(s),tagset = None) # returns the parts of speech of every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'absorb'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lemmatizer so each token is converted to its root\n",
    "lemma = wordnet.WordNetLemmatizer()\n",
    "lemma.lemmatize('absorbed', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that performs text normalization steps\n",
    "\n",
    "def normalization(text):\n",
    "    \n",
    "    text = str(text).lower() # text to lower case\n",
    "    clean_text = re.sub(r'[^ a-z]','',text) # removing special characters\n",
    "    tokens = nltk.word_tokenize(clean_text) # word tokenizing\n",
    "    \n",
    "    lema = wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    lema_words = []\n",
    "    \n",
    "    tags_list = pos_tag(tokens,tagset=None) # parts of speech\n",
    "    \n",
    "    # Lemmatize all the words in given sentence by assigning correct category\n",
    "    for token,syntactic_func in tags_list:\n",
    "        if syntactic_func.startswith('V'):  # Verb\n",
    "            pos_val = 'v'\n",
    "        elif syntactic_func.startswith('J'): # Adj\n",
    "            pos_val = 'a'\n",
    "        elif syntactic_func.startswith('R'): # Adverb\n",
    "            pos_val = 'r'\n",
    "        else:\n",
    "            pos_val = 'n' # Noun\n",
    "        lemmatized_word = lema.lemmatize(token, pos_val) # lemmatize\n",
    "        lema_words.append(lemmatized_word) # appending the lemmatized token\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i be think about what you will be tell me'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test of normalization function\n",
    "normalization('i was thinking about what you will be telling me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "      <th>Lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>I'll be back</td>\n",
       "      <td>All right. I'll be here.</td>\n",
       "      <td>ill be back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>I'll get back to you in a moment</td>\n",
       "      <td>Till next time.</td>\n",
       "      <td>ill get back to you in a moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>I promise to come back</td>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>i promise to come back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>I promise to come back</td>\n",
       "      <td>Okay. You know where to find me.</td>\n",
       "      <td>i promise to come back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>How large is the moon</td>\n",
       "      <td>A pretty large number of miles</td>\n",
       "      <td>how large be the moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Big is moon</td>\n",
       "      <td>A pretty large number of miles</td>\n",
       "      <td>big be moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>How far away is the sun</td>\n",
       "      <td>A pretty large number of miles</td>\n",
       "      <td>how far away be the sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Do you know where the sun is</td>\n",
       "      <td>I'm blind</td>\n",
       "      <td>do you know where the sun be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>Do you drive</td>\n",
       "      <td>No</td>\n",
       "      <td>do you drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>Do you smoke</td>\n",
       "      <td>No</td>\n",
       "      <td>do you smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Do you have family</td>\n",
       "      <td>No</td>\n",
       "      <td>do you have family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>Are there others like you</td>\n",
       "      <td>Of course. That's why we're here</td>\n",
       "      <td>be there others like you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Do you want to take over the world</td>\n",
       "      <td>Of course. That's why we're here</td>\n",
       "      <td>do you want to take over the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>Who are we?</td>\n",
       "      <td>You don't need to know</td>\n",
       "      <td>who be we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Who is we?</td>\n",
       "      <td>You don't need to know</td>\n",
       "      <td>who be we</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Context                     Text Response  \\\n",
       "1589                        I'll be back          All right. I'll be here.   \n",
       "1590    I'll get back to you in a moment                   Till next time.   \n",
       "1591              I promise to come back  Okay. You know where to find me.   \n",
       "1592              I promise to come back  Okay. You know where to find me.   \n",
       "1593               How large is the moon    A pretty large number of miles   \n",
       "1594                         Big is moon    A pretty large number of miles   \n",
       "1595             How far away is the sun    A pretty large number of miles   \n",
       "1596        Do you know where the sun is                         I'm blind   \n",
       "1597                        Do you drive                                No   \n",
       "1598                        Do you smoke                                No   \n",
       "1599                  Do you have family                                No   \n",
       "1600           Are there others like you  Of course. That's why we're here   \n",
       "1601  Do you want to take over the world  Of course. That's why we're here   \n",
       "1602                         Who are we?            You don't need to know   \n",
       "1603                          Who is we?            You don't need to know   \n",
       "\n",
       "                         Lemmatized_text  \n",
       "1589                         ill be back  \n",
       "1590     ill get back to you in a moment  \n",
       "1591              i promise to come back  \n",
       "1592              i promise to come back  \n",
       "1593               how large be the moon  \n",
       "1594                         big be moon  \n",
       "1595             how far away be the sun  \n",
       "1596        do you know where the sun be  \n",
       "1597                        do you drive  \n",
       "1598                        do you smoke  \n",
       "1599                  do you have family  \n",
       "1600            be there others like you  \n",
       "1601  do you want to take over the world  \n",
       "1602                           who be we  \n",
       "1603                           who be we  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize whole dataset (user input text)\n",
    "df['Lemmatized_text'] = df['Context'].apply(normalization)\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition: with corpus of words and frequency of these, we can compare similarity between documents and learn information form these documents throught the presence of the 'target words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was the best of times',\n",
       " 'it was the worst of times',\n",
       " 'it was the age of wisdom',\n",
       " 'it was the age of foolishness']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Attempt of BoW model with small corpus of text (model intuition from https://machinelearningmastery.com/gentle-introduction-bag-words-model/)\n",
    "c = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness\"\n",
    "corpus = [i for i in c.split(', ')]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0, 1, 1, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0, 1, 0, 1]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vector using target words\n",
    "targets = ['it', 'was', 'the', 'best', 'of', 'times', 'worst', 'age', 'wisdom', 'foolishness']\n",
    "vectors = []\n",
    "for verse in corpus:\n",
    "    vector = []\n",
    "    verse = [i for i in verse.lower().split()]\n",
    "    for word in targets:\n",
    "        if word in verse:\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    vectors.append(vector)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NLTK and current corpus to apply BOW model to chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abort</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>actually</th>\n",
       "      <th>adore</th>\n",
       "      <th>advice</th>\n",
       "      <th>advise</th>\n",
       "      <th>affirmative</th>\n",
       "      <th>afraid</th>\n",
       "      <th>...</th>\n",
       "      <th>yeh</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>youre</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abort  about  absolutely  abysmal  actually  adore  advice  advise  \\\n",
       "0         0      1           0        0         0      0       0       0   \n",
       "1         0      0           0        0         0      0       0       0   \n",
       "2         0      0           0        0         0      0       0       0   \n",
       "3         0      0           0        0         0      0       0       0   \n",
       "4         0      1           0        0         0      0       0       0   \n",
       "...     ...    ...         ...      ...       ...    ...     ...     ...   \n",
       "1599      0      0           0        0         0      0       0       0   \n",
       "1600      0      0           0        0         0      0       0       0   \n",
       "1601      0      0           0        0         0      0       0       0   \n",
       "1602      0      0           0        0         0      0       0       0   \n",
       "1603      0      0           0        0         0      0       0       0   \n",
       "\n",
       "      affirmative  afraid  ...  yeh  yep  yes  yet  you  your  youre  yours  \\\n",
       "0               0       0  ...    0    0    0    0    0     1      0      0   \n",
       "1               0       0  ...    0    0    0    0    1     0      0      0   \n",
       "2               0       0  ...    0    0    0    0    0     0      0      0   \n",
       "3               0       0  ...    0    0    0    0    0     0      0      0   \n",
       "4               0       0  ...    0    0    0    0    0     0      0      0   \n",
       "...           ...     ...  ...  ...  ...  ...  ...  ...   ...    ...    ...   \n",
       "1599            0       0  ...    0    0    0    0    1     0      0      0   \n",
       "1600            0       0  ...    0    0    0    0    1     0      0      0   \n",
       "1601            0       0  ...    0    0    0    0    1     0      0      0   \n",
       "1602            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "1603            0       0  ...    0    0    0    0    0     0      0      0   \n",
       "\n",
       "      yourself  yup  \n",
       "0            0    0  \n",
       "1            0    0  \n",
       "2            1    0  \n",
       "3            1    0  \n",
       "4            1    0  \n",
       "...        ...  ...  \n",
       "1599         0    0  \n",
       "1600         0    0  \n",
       "1601         0    0  \n",
       "1602         0    0  \n",
       "1603         0    0  \n",
       "\n",
       "[1604 rows x 515 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use CountVectorizer method to improve performance\n",
    "cv = CountVectorizer() # intializing the count vectorizer\n",
    "X = cv.fit_transform(df['Lemmatized_text']).toarray()\n",
    "# returns all the unique word from data \n",
    "features = cv.get_feature_names()\n",
    "df_bow = pd.DataFrame(X, columns = features)\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Are you a bot'\n",
    "query1 ='Will you help me and tell me more about yourself' \n",
    "Q = []\n",
    "a = query.split()\n",
    "for i in a:\n",
    "    if i in stopwords.words('english'):\n",
    "        continue\n",
    "    else:\n",
    "        Q.append(i)\n",
    "    b=\" \".join(Q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_lemma = normalization(b) # applying the function that we created for text normalizing\n",
    "query_BOW = cv.transform([query_lemma]).toarray() # applying bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use trigonometric functions (cosine similarity) to determine 0-1 value of each vector, facilitating comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [0.40824829],\n",
       "       [0.40824829]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity for the test query\n",
    "cosine_value = 1 - pairwise_distances(df_bow, query_BOW, metric = 'cosine' )\n",
    "(cosine_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity_bow'] = cosine_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am a bot. I am designed to keep conversation...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>Of course. That's why we're here</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Of course. That's why we're here</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>You don't need to know</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>You don't need to know</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text Response  similarity_bow\n",
       "0           Just think of me as the ace up your sleeve.        0.000000\n",
       "1     I am a bot. I am designed to keep conversation...        0.000000\n",
       "2     I am a bot. I am designed to keep conversation...        0.000000\n",
       "3     I am a bot. I am designed to keep conversation...        0.000000\n",
       "4     I am a bot. I am designed to keep conversation...        0.000000\n",
       "...                                                 ...             ...\n",
       "1599                                                 No        0.000000\n",
       "1600                   Of course. That's why we're here        0.316228\n",
       "1601                   Of course. That's why we're here        0.000000\n",
       "1602                             You don't need to know        0.408248\n",
       "1603                             You don't need to know        0.408248\n",
       "\n",
       "[1604 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi = pd.DataFrame(df, columns=['Text Response','similarity_bow']) # taking similarity value of responses for the question we took\n",
    "df_simi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Lovely, thanks.</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I'm definitely working on it.</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Text Response  similarity_bow\n",
       "226   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "228   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "224   Indeed I am. I'll be here whenever you need me.        0.707107\n",
       "1228                                  Lovely, thanks.        0.534522\n",
       "95                      I'm definitely working on it.        0.500000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simi_sort = df_simi.sort_values(by='similarity_bow', ascending=False) # sorting the values\n",
    "df_simi_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Response</th>\n",
       "      <th>similarity_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Indeed I am. I'll be here whenever you need me.</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Lovely, thanks.</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I'm definitely working on it.</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Thank you.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sorry to make you feel so.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sorry to make you feel so.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sorry to make you feel so.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Thank you.</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Text Response  similarity_bow\n",
       "226   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "228   Indeed I am. I'll be here whenever you need me.        0.816497\n",
       "224   Indeed I am. I'll be here whenever you need me.        0.707107\n",
       "1228                                  Lovely, thanks.        0.534522\n",
       "95                      I'm definitely working on it.        0.500000\n",
       "...                                               ...             ...\n",
       "260                                        Thank you.        0.353553\n",
       "38                         Sorry to make you feel so.        0.353553\n",
       "36                         Sorry to make you feel so.        0.353553\n",
       "39                         Sorry to make you feel so.        0.353553\n",
       "264                                        Thank you.        0.353553\n",
       "\n",
       "[333 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.35 # considering the value of p=smiliarity > 0.35\n",
    "df_threshold = df_simi_sort[df_simi_sort['similarity_bow'] > threshold] \n",
    "df_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_value = cosine_value.argmax() # index in dataframe of of highest similarity\n",
    "index_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you a bot'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Indeed I am. I'll be here whenever you need me.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text Response'].loc[index_value] # Get response for highest-similarity index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Will help tell'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function that removes stop words and process the corpus\n",
    "def stopword_(text):      \n",
    "    lema = wordnet.WordNetLemmatizer() # intializing lemmatization\n",
    "    lema_words = []\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text) # word tokenizing\n",
    "    tags_list = pos_tag(tokens,tagset=None) # parts of speech\n",
    "    \n",
    "    words_to_remove = stopwords.words('english')\n",
    "    \n",
    "    # Lemmatize all the words in given sentence by assigning correct category\n",
    "    for token,syntactic_func in tags_list:\n",
    "        if token in words_to_remove:\n",
    "            continue\n",
    "        if syntactic_func.startswith('V'):  # Verb\n",
    "            pos_val = 'v'\n",
    "        elif syntactic_func.startswith('J'): # Adj\n",
    "            pos_val = 'a'\n",
    "        elif syntactic_func.startswith('R'): # Adverb\n",
    "            pos_val = 'r'\n",
    "        else:\n",
    "            pos_val = 'n' # Noun\n",
    "        lemmatized_word = lema.lemmatize(token, pos_val) # lemmatize\n",
    "        lema_words.append(lemmatized_word) # append the lemmatized token\n",
    "    \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence \n",
    "stopword_(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm glad to help. What can I do for you?\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that returns response to query using BOW model\n",
    "\n",
    "def chat(text):\n",
    "    s = stopword_(text)\n",
    "    lemma = normalization(s) # calling the function to perform text normalization\n",
    "    bow=cv.transform([lemma]).toarray() # applying bow\n",
    "    cosine_value = 1- pairwise_distances(df_bow,bow, metric = 'cosine' )\n",
    "    index_value=cosine_value.argmax() # getting index value \n",
    "    return df['Text Response'].loc[index_value]\n",
    "chat(query1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
